{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hmm.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMBBScgJpjqxcCelHF6EFU+"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"bznNL3lM6hIV","colab_type":"code","outputId":"b9993384-e9a0-4ef0-c60a-54bbd6853203","executionInfo":{"status":"ok","timestamp":1590748883774,"user_tz":-420,"elapsed":1074,"user":{"displayName":"Duy Trình Đức","photoUrl":"","userId":"15551007784781145361"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":161,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8CIjNHvk7Gr_","colab_type":"code","outputId":"ea3a8922-965a-4a05-a28a-3603a6b78e06","executionInfo":{"status":"ok","timestamp":1590740989950,"user_tz":-420,"elapsed":53453,"user":{"displayName":"Duy Trình Đức","photoUrl":"","userId":"15551007784781145361"}},"colab":{"base_uri":"https://localhost:8080/","height":99}},"source":["pip install git+https://github.com/librosa/librosa"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/librosa/librosa\n","  Cloning https://github.com/librosa/librosa to /tmp/pip-req-build-2yw1y3b2\n","  Running command git clone -q https://github.com/librosa/librosa /tmp/pip-req-build-2yw1y3b2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BTQD43k163jV","colab_type":"code","colab":{}},"source":["pip install hmmlearn"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ridlwGl602_","colab_type":"code","colab":{}},"source":["\n","import librosa\n","import numpy as np\n","import os\n","import math\n","from sklearn.cluster import KMeans\n","import hmmlearn.hmm"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"am7UQejI7Nml","colab_type":"code","colab":{}},"source":["def get_mfcc(file_path):\n","    y, sr = librosa.load(file_path) # read .wav file\n","    hop_length = math.floor(sr*0.010) # 10ms hop\n","    win_length = math.floor(sr*0.025) # 25ms frame\n","    # mfcc is 12 x T matrix\n","    mfcc = librosa.feature.mfcc(\n","        y, sr, n_mfcc=12, n_fft=1024,\n","        hop_length=hop_length, win_length=win_length)\n","    # substract mean from mfcc --> normalize mfcc\n","    mfcc = mfcc - np.mean(mfcc, axis=1).reshape((-1,1)) \n","    # delta feature 1st order and 2nd order\n","    delta1 = librosa.feature.delta(mfcc, order=1)\n","    delta2 = librosa.feature.delta(mfcc, order=2)\n","    # X is 36 x T\n","    X = np.concatenate([mfcc, delta1, delta2], axis=0) # O^r\n","    # return T x 36 (transpose of X)\n","    return X.T # hmmlearn use T x N matrix\n","\n","def get_class_data(data_dir):\n","    files = os.listdir(data_dir)\n","    mfcc = [get_mfcc(os.path.join(data_dir,f)) for f in files if f.endswith(\".wav\")]\n","    return mfcc\n","\n","def clustering(X, n_clusters=10):\n","    kmeans = KMeans(n_clusters=n_clusters, n_init=50, random_state=0, verbose=0)\n","    kmeans.fit(X)\n","    print(\"centers\", kmeans.cluster_centers_.shape)\n","    return kmeans  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4fYZ9zec7X70","colab_type":"code","colab":{}},"source":["if __name__ == \"__main__\":\n","    class_names = [\"di\", \"ra\", \"va\", \"yte\", \"nguoi\",\"test_di\", \"test_ra\", \"test_va\", \"test_yte\", \"test_nguoi\"]\n","    dataset = {}\n","    for cname in class_names:\n","        print(f\"Load {cname} dataset\")\n","        dataset[cname] = get_class_data(os.path.join(\"/content/drive/My Drive/data\", cname))\n","\n","    # Get all vectors in the datasets\n","    all_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in dataset.items()], axis=0)\n","    print(\"vectors\", all_vectors.shape)\n","    # Run K-Means algorithm to get clusters\n","    kmeans = clustering(all_vectors)\n","    print(\"centers\", kmeans.cluster_centers_.shape)\n","\n","    models = {}\n","    for cname in class_names:\n","        class_vectors = dataset[cname]\n","        # convert all vectors to the cluster index\n","        # dataset['one'] = [O^1, ... O^R]\n","        # O^r = (c1, c2, ... ct, ... cT)\n","        # O^r size T x 1\n","        \n","        dataset[cname] = list([kmeans.predict(v).reshape(-1,1) for v in dataset[cname]])\n","\n","        if cname == 'di':\n","          hmm = hmmlearn.hmm.MultinomialHMM(\n","            n_components=6, random_state=0, n_iter=1000, verbose=True,\n","            startprob_prior=np.array([0.7,0.2,0.1,0.0,0.0,0.0]),\n","            transmat_prior=np.array([\n","                [0.4,0.5,0.1,0.0,0.0,0.0,],\n","                [0.0,0.4,0.5,0.1,0.0,0.0,],\n","                [0.0,0.0,0.4,0.5,0.1,0.0,],\n","                [0.0,0.0,0.0,0.4,0.5,0.1,],\n","                [0.0,0.0,0.0,0.0,0.4,0.6,],\n","                [0.0,0.0,0.0,0.0,0.0,1.0,],\n","            ]),\n","          )\n","        elif cname == 'ra':\n","          hmm = hmmlearn.hmm.MultinomialHMM(\n","            n_components=6, random_state=0, n_iter=1000, verbose=True,\n","            startprob_prior=np.array([0.7,0.2,0.1,0.0,0.0,0.0]),\n","            transmat_prior=np.array([\n","                [0.3,0.6,0.1,0.0,0.0,0.0,],\n","                [0.0,0.3,0.6,0.1,0.0,0.0,],\n","                [0.0,0.0,0.3,0.6,0.1,0.0,],\n","                [0.0,0.0,0.0,0.3,0.6,0.1,],\n","                [0.0,0.0,0.0,0.0,0.3,0.7,],\n","                [0.0,0.0,0.0,0.0,0.0,1.0,],\n","            ]),\n","          )\n","        elif cname == 'va':\n","          hmm = hmmlearn.hmm.MultinomialHMM(\n","            n_components=6, random_state=0, n_iter=1000, verbose=True,\n","            startprob_prior=np.array([0.7,0.2,0.1,0.0,0.0,0.0]),\n","            transmat_prior=np.array([\n","                [0.7,0.2,0.1,0.0,0.0,0.0,],\n","                [0.0,0.7,0.2,0.1,0.0,0.0,],\n","                [0.0,0.0,0.7,0.2,0.1,0.0,],\n","                [0.0,0.0,0.0,0.7,0.2,0.1,],\n","                [0.0,0.0,0.0,0.0,0.7,0.3,],\n","                [0.0,0.0,0.0,0.0,0.0,1.0,],\n","            ]),\n","          )\n","        elif cname == 'yte':\n","          hmm = hmmlearn.hmm.MultinomialHMM(\n","            n_components=9, random_state=0, n_iter=1000, verbose=True,\n","            startprob_prior=np.array([0.7,0.2,0.1,0.0,0.0,0.0,0.0,0.0,0.0]),\n","            transmat_prior=np.array([\n","                [0.2,0.5,0.2,0.1,0.0,0.0,0.0,0.0,0.0,],\n","                [0.0,0.2,0.5,0.2,0.1,0.0,0.0,0.0,0.0,],\n","                [0.0,0.0,0.2,0.5,0.2,0.1,0.0,0.0,0.0,],\n","                [0.0,0.0,0.0,0.2,0.5,0.2,0.1,0.0,0.0,],\n","                [0.0,0.0,0.0,0.0,0.2,0.5,0.2,0.1,0.0,],\n","                [0.0,0.0,0.0,0.0,0.0,0.2,0.5,0.2,0.1,],\n","                [0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.6,0.2,],\n","                [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.7,],\n","                [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,],\n","            ]),\n","          )\n","        elif cname == 'nguoi':\n","          hmm = hmmlearn.hmm.MultinomialHMM(\n","            n_components=12, random_state=0, n_iter=1000, verbose=True,\n","            startprob_prior=np.array([0.7,0.2,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]),\n","            transmat_prior=np.array([\n","                [0.4,0.5,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,],\n","                [0.0,0.4,0.5,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,],\n","                [0.0,0.0,0.4,0.5,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,],\n","                [0.0,0.0,0.0,0.4,0.5,0.1,0.0,0.0,0.0,0.0,0.0,0.0,],\n","                [0.0,0.0,0.0,0.0,0.4,0.5,0.1,0.0,0.0,0.0,0.0,0.0,],\n","                [0.0,0.0,0.0,0.0,0.0,0.4,0.5,0.1,0.0,0.0,0.0,0.0,],\n","                [0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.5,0.1,0.0,0.0,0.0,],\n","                [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.5,0.1,0.0,0.0,],\n","                [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.5,0.1,0.0,],\n","                [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.5,0.1,],\n","                [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.5,],\n","                [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,],\n","            ]),\n","          )\n","\n","        if cname[:4] != 'test':\n","            X = np.concatenate(dataset[cname])\n","            lengths = list([len(x) for x in dataset[cname]])\n","            print(\"training class\", cname)\n","            print(X.shape, lengths, len(lengths))\n","            hmm.fit(X, lengths=lengths)\n","            models[cname] = hmm\n","    print(\"Training done\")\n","\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P-EhW3O4RyJX","colab_type":"code","colab":{}},"source":["print(\"Testing\")\n","for true_cname in class_names:\n","  for O in dataset[true_cname]:\n","    if true_cname[:4] == 'test':\n","      score = {cname : model.score(O, [len(O)]) for cname, model in models.items() if cname[:4] != 'test' }\n","      print(true_cname, score)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vQlO_6AuZoIK","colab_type":"code","colab":{}},"source":["print(\"Testing\")\n","to_test = ['test_di', 'test_ra', 'test_va', 'test_yte', 'test_nguoi']\n","for true_cname in to_test:\n","    correct = 0\n","    failed = 0\n","    real_name = true_cname.split('_')[-1]\n","\n","    for O in dataset[true_cname]:\n","        score = {cname : model.score(O, [len(O)]) for cname, model in models.items() if cname[:4] != 'test' }\n","\n","        match = True\n","        for key in score:\n","            if score[key] > score[real_name]:\n","                match = False\n","        if match:\n","            correct += 1\n","        else:\n","            failed += 1\n","            # print(real_name, score)\n","\n","    acc = correct/(correct+failed)\n","    print(real_name + \" : \" + str(acc))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ey4ntm_s6-k9","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}